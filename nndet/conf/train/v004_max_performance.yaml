# @package __global__
defaults:
  - augmentation: base_more

module: RetinaUNetV004
predictor: BoxPredictorSelective

plan: D3V001_3d
planner: D3V001

augment_cfg:
  augmentation: ${augmentation}
  num_train_batches_per_epoch: ${trainer_cfg.num_train_batches_per_epoch}
  num_val_batches_per_epoch: ${trainer_cfg.num_val_batches_per_epoch}

  dataloader: "DataLoader{}DOffset"
  oversample_foreground_percent: 0.5
  dataloader_kwargs: {}

  # 最大性能数据加载配置
  num_threads: ${oc.env:det_num_threads, "20"}  # 进一步增加线程数
  num_cached_per_thread: 6  # 增加缓存以减少I/O等待
  multiprocessing: True

  # 最大batch size配置（充分利用24GB显存）
  batch_size: 12  # 进一步增加到12（需要监控显存使用情况）

trainer_cfg:
  gpus: 1
  accelerator:
  precision: 16
  amp_backend: native
  amp_level: O1
  
  # 最大性能设置
  deterministic: False
  benchmark: True  # 启用cudnn benchmark
  
  monitor_key: "mAP_IoU_0.10_0.50_0.05_MaxDet_100"
  monitor_mode: "max"

  max_num_epochs: 50
  num_train_batches_per_epoch: 1600  # 由于batch size增加，减少批次数
  num_val_batches_per_epoch: 65

  # 适应更大batch size的学习率
  initial_lr: 0.03  # 进一步提高学习率
  sgd_momentum: 0.9
  sgd_nesterov: True
  weight_decay: 3.e-5

  warm_iterations: 2500
  warm_lr: 1.e-6

  poly_gamma: 0.9
  swa_epochs: 10

model_cfg:
  encoder_kwargs: {}
  decoder_kwargs:
    min_out_channels: 8
    upsampling_mode: "transpose"
    num_lateral: 1
    norm_lateral: False
    activation_lateral: False
    num_out: 1
    norm_out: False
    activation_out: False

  head_kwargs: {}

  head_classifier_kwargs:
    num_convs: 1
    norm_channels_per_group: 16
    norm_affine: True
    reduction: "mean"
    loss_weight: 1.
    prior_prob: 0.01

  head_regressor_kwargs:
    num_convs: 1
    norm_channels_per_group: 16
    norm_affine: True
    reduction: "sum"
    loss_weight: 1.
    learn_scale: True

  head_sampler_kwargs:
    batch_size_per_image: 64  # 进一步增加采样数
    positive_fraction: 0.33
    pool_size: 25  # 增加负样本池
    min_neg: 1

  segmenter_kwargs:
    dice_kwargs:
      batch_dice: True

  matcher_kwargs:
    num_candidates: 4
    center_in_gt: False

  vessel_attention_kwargs:
    enable: True
    fusion_mode: "concatenation"
    attention_channels: 8
    use_sigmoid: True
    spatial_scale: 1.0

  plan_arch_overwrites: 
    batch_size: 12  # 覆盖为最大batch size
  plan_anchors_overwrites: {} 